{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786",
   "metadata": {
    "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786"
   },
   "source": [
    "# Lab | Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8882fc-4815-4567-92fa-b4816358ba7d",
   "metadata": {
    "id": "ce8882fc-4815-4567-92fa-b4816358ba7d"
   },
   "source": [
    "Welcome to the IMDb Web Scraping Adventure Lab!\n",
    "\n",
    "**Objective**\n",
    "\n",
    "In this lab, we will embark on a mission to unearth valuable insights from the vast sea of data available on IMDb, one of the largest online databases of movie, TV, and celebrity information. As budding data scientists and business analysts, you have been tasked to scrape a specific subset of data from IMDb to assist film production companies in understanding the landscape of highly-rated movies in a defined time period. Your insights will potentially influence the making of the next netflix movie!\n",
    "\n",
    "**Background**\n",
    "\n",
    "In a world where data has become the new currency, businesses are leveraging big data to make informed decisions that drive success and profitability. The entertainment industry, being no exception, utilizes data analytics to comprehend market trends, audience preferences, and the performance of films based on various parameters such as director, genre, stars involved, etc. IMDb stands as a goldmine of such data, offering intricate details of almost every movie ever made.\n",
    "\n",
    "**Task**\n",
    "\n",
    "Your task is to create a Python script using `BeautifulSoup` and `pandas` to scrape IMDb movie data based on user ratings and release dates. This script should be able to filter movies with ratings above a certain threshold and within a specified date range.\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "- A function named `scrape_imdb` that takes four parameters: `title_type`,`user_rating`, `start_date`, and `end_date`.\n",
    "- The function should return a DataFrame with the following columns:\n",
    "  - **Movie Nr**: The number representing the movie’s position in the list.  xxxxxxxxxxx\n",
    "  - **Title**: The title of the movie.                     xxxxxxxxxxxxxxxxxxxxxx\n",
    "  - **Year**: The year the movie was released.           xxxxxxxxxxxxxxxxxxx\n",
    "  - **Rating**: The IMDb rating of the movie.            xxxxxxxxxxxxxxxxxxxx\n",
    "  - **Runtime (min)**: The duration of the movie in minutes.   xxxxxxxxxxxxxxxxx\n",
    "  - **Genre**: The genre of the movie.\n",
    "  - **Description**: A brief description of the movie.                  xxxxxxxxxxxxxx\n",
    "  - **Director**: The director of the movie.\n",
    "  - **Stars**: The main stars of the movie.\n",
    "  - **Votes**: The number of votes the movie received.          XXXXXXXXXXXXXXX\n",
    "  - **Gross ($M)**: The gross earnings of the movie in millions of USD.\n",
    "\n",
    "You will execute this script to scrape data for movies with the Title Type `Feature Film` that have a user rating of `7.5 and above` and were released between `January 1, 1990, and December 31, 1992`.\n",
    "\n",
    "Remember to experiment with different title types, dates and ratings to ensure your code is versatile and can handle various searches effectively!\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "- [IMDb Advanced Search](https://www.imdb.com/search/title/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519921d-5890-445b-9a33-934ed8ee378c",
   "metadata": {
    "id": "3519921d-5890-445b-9a33-934ed8ee378c"
   },
   "source": [
    "**Hint**\n",
    "\n",
    "Your first mission is to familiarize yourself with the IMDb advanced search page. Head over to [IMDb advanced search](https://www.imdb.com/search/title/) and input the following parameters, keeping all other fields to their default values or blank:\n",
    "\n",
    "- **Title Type**: Feature film\n",
    "- **Release date**: From 1990 to 1992 (Note: You don't need to specify the day and month)\n",
    "- **User Rating**: 7.5 to -\n",
    "\n",
    "Upon searching, you'll land on a page showcasing a list of movies, each displaying vital details such as the title, release year, and crew information. Your task is to scrape this treasure trove of data.\n",
    "\n",
    "Carefully examine the resulting URL and construct your own URL to include all the necessary parameters for filtering the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a83a0d-a742-49f6-985e-e27887cbf922",
   "metadata": {
    "id": "25a83a0d-a742-49f6-985e-e27887cbf922"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Best of luck! Immerse yourself in the world of books, and may the data be with you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0",
   "metadata": {
    "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0"
   },
   "source": [
    "**Important note**:\n",
    "\n",
    "In the fast-changing online world, websites often get updates and make changes. When you try this lab, the IMDb website might be different from what we expect.\n",
    "\n",
    "If you run into problems because of these changes, like new rules or things that stop you from getting data, don't worry! Instead, get creative.\n",
    "\n",
    "You can choose another website that interests you and is good for scraping data. Websites like Wikipedia or The New York Times are good options. The main goal is still the same: get useful data and learn how to scrape it from a website that you find interesting. It's a chance to practice your web scraping skills and explore a source of information you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40359eee-9cd7-4884-bfa4-83344c222305",
   "metadata": {
    "id": "40359eee-9cd7-4884-bfa4-83344c222305"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aea403-6615-4030-8d0b-19fccedfa507",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=1990-01-01,1992-12-31&user_rating=7.5,10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ec7f7-a84d-4d5d-a856-02fb1dd41c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Request successful\")\n",
    "else:\n",
    "    print(\"Error: \", response.status_code)\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f391667-ca8e-42b1-8281-54057ecf13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af90608-dd5a-48af-bc0d-5903c0052352",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ffd2f0-1b35-4251-93c6-791984a92879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.headers['Content-Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93354722-6125-4d32-8212-a0ae9b69d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3375aa-ed1a-4a00-83b7-e11c795d673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8c2bd-07c1-448e-9ec8-7a358afc436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())  # This formats the HTML in a readable way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd88f54-f38c-4e4b-9915-18a685c9785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"title\") # Find the first <title> tag on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3b05e-da47-4d7d-95e5-9a37ea3fdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"title\") # Find the all <title> tags on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9fb836-ebb3-4509-b932-5ff11415c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOMBRE Y NÚMERO EN LA LISTA\n",
    "\n",
    "#<h3 class=\"ipc-title__text\">1. Mi pobre angelito</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144128c-c98a-4dd0-b5e7-0d7f0ae8311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "films = []\n",
    "for film in soup.find_all(\"h3\", class_ = \"ipc-title__text\"):\n",
    "    films.append(film.get_text(strip=True))\n",
    "\n",
    "films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42d33a-22f8-4f2c-b145-b4106ed11a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_nr = []\n",
    "\n",
    "for film in films:\n",
    "    match = re.match(r'^\\d+', film)\n",
    "    if match:\n",
    "        movie_nr.append(int(match.group()))\n",
    "\n",
    "print(movie_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92367c35-73f1-4ba8-8faf-5285cb841f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for x in films:\n",
    "    match = re.match(r'^\\d+\\.\\s*(.*)', x)\n",
    "    if match:\n",
    "        titles.append(match.group(1))\n",
    "    else:\n",
    "        titles.append(x)\n",
    "\n",
    "first_25_titles = titles[:25]\n",
    "\n",
    "print(first_25_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959c1ce-86f6-4c74-bef6-5da7ca7bfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AÑO\n",
    "\n",
    "#<span class=\"sc-300a8231-7 eaXxft dli-title-metadata-item\">1990</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca7471-07bc-4066-a58e-64f13b7296ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = soup.find_all(\"span\", class_ = \"sc-300a8231-7 eaXxft dli-title-metadata-item\")\n",
    "spans #sc-300a8231-7 eaXxft dli-title-metadata-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779055a-45fa-4de8-bf39-18a4f31986c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for span in spans:\n",
    "    text = span.text\n",
    "    if text.isdigit() and len(text) == 4:\n",
    "        years.append(text)\n",
    "\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0761b5-d0e7-44e6-a6e0-f77d0d673dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = soup.find('span', class_='sc-300a8231-7 eaXxft dli-title-metadata-item').text\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaa0d3-7f66-4bea-8937-0a385acdbca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RATING\n",
    "\n",
    "#ratting = <span class=\"ipc-rating-star--rating\">7.7</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5f6fb-133e-476c-8d7b-e881bc6bb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_ratings = soup.find_all(\"span\", class_ = \"ipc-rating-star--rating\")\n",
    "spans_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739526d2-153f-4dc9-a3b3-654fb1c783e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "\n",
    "for span in spans_ratings:\n",
    "    text = span.get_text()\n",
    "    numbers = re.findall(r'\\d+\\.\\d+', text)\n",
    "    ratings.extend(float(num) for num in numbers)\n",
    "\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501aacef-05c4-43b6-a12a-228ed906acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = re.findall(r'\\d+\\.\\d+', html_string)\n",
    "number = float(numbers[0]) if numbers else None\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d62cb7-add3-4f81-8958-383ccc29134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN TIME\n",
    "\n",
    "#<span class=\"sc-300a8231-7 eaXxft dli-title-metadata-item\">1h 43m</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54247ba5-173f-4bfb-8bca-27bd2729fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = [span.get_text(strip=True) for span in spans if 'h' in span.get_text() or 'm' in span.get_text()]\n",
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471601aa-6828-4500-8542-a23e99966525",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = soup.find('span', class_=\"sc-300a8231-7 eaXxft dli-title-metadata-item\").text\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea69a42-731d-4088-a1e5-e62eb229a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCRIPTION\n",
    "\n",
    "#<div class=\"ipc-html-content-inner-div\" role=\"presentation\">Un travieso niño de ocho años debe proteger su casa de unos ladrones cuando es accidentalmente olvidado en casa por su familia cuando se van de vacaciones de Navidad.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa8c23-3b0e-43d1-afba-2593eb1cb518",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_descriptions = soup.find_all('div', class_='ipc-html-content-inner-div')\n",
    "div_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6ba04-0c7b-490d-b37c-fbf1118d3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = []\n",
    "\n",
    "for div in div_descriptions:\n",
    "    description = div.get_text()\n",
    "    descriptions.append(description)\n",
    "\n",
    "print(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800cceb-c870-4e6d-8de2-0a55341e2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTES\n",
    "\n",
    "#<span class=\"ipc-rating-star--voteCount\">&nbsp;(<!-- -->688&nbsp;k<!-- -->)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558b8ce-50de-4c10-b78d-d5a65b28e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_votes = soup.find_all(\"span\", class_ = \"ipc-rating-star--voteCount\")\n",
    "spans_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c445a-7322-41a8-a68c-f43c57741ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = []\n",
    "\n",
    "for span in spans_votes:\n",
    "    text = span.get_text()\n",
    "    match = re.match(r'\\s*\\(([\\d.]+)([KM])\\)', text)\n",
    "    if match:\n",
    "        number = float(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        \n",
    "        if unit == 'K':\n",
    "            votes.append(int(number * 1_000))\n",
    "        elif unit == 'M':\n",
    "            votes.append(int(number * 1_000_000))\n",
    "\n",
    "print(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542c9cb-03a6-42a9-9a1e-fe0dfee764f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#<h3 class=\"ipc-title__text\">1. Mi pobre angelito</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374f130-96c9-45aa-8c1d-27a50499c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imdb_url():\n",
    "    title_type = input(\"Enter the Title Type: \")\n",
    "    start_date = input(\"Enter the Start Date: \")\n",
    "    end_date = input(\"Enter the End Date: \")\n",
    "    user_rating = input(\"Enter the User Rating: \")\n",
    "    \n",
    "    url = f\"https://www.imdb.com/search/title/?title_type={title_type}&release_date={start_date},{end_date}&user_rating={user_rating},10\"\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f6758-9eec-4194-b319-5a6b12e1b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.imdb.com/search/title/?title_type=feature&release_date=1990-01-01,1992-12-31&user_rating=7.5,10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748c82e-43c9-4cda-9aae-6d9b356a18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_response(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Request successful\")\n",
    "    else:\n",
    "        print(\"Error: \", response.status_code)\n",
    "    \n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf1a4d-9946-407b-815d-d46e602a293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def create_imdb_url():\n",
    "    title_type = input(\"Enter the Title Type: \")\n",
    "    start_date = input(\"Enter the Start Date (YYYY-MM-DD): \")\n",
    "    end_date = input(\"Enter the End Date (YYYY-MM-DD): \")\n",
    "    user_rating = input(\"Enter the User Rating: \")\n",
    "    \n",
    "    url = f\"https://www.imdb.com/search/title/?title_type={title_type}&release_date={start_date},{end_date}&user_rating={user_rating},10\"\n",
    "    \n",
    "    return url\n",
    "\n",
    "def scrape_imdb(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    films = []\n",
    "    for film in soup.find_all(\"h3\", class_ = \"ipc-title__text\"):\n",
    "        films.append(film.get_text(strip=True))\n",
    "    \n",
    "    films\n",
    "\n",
    "    movie_nr = []\n",
    "\n",
    "    for film in films:\n",
    "        match = re.match(r'^\\d+', film) #inicio de la cadena, busca números\n",
    "        if match:\n",
    "            movie_nr.append(int(match.group()))\n",
    "\n",
    "    titles = []\n",
    "\n",
    "    for x in films:\n",
    "        match = re.match(r'^\\d+\\.\\s*(.*)', x)#inicio de la cadena, busca números y captura lo que está después del punto\n",
    "        if match:\n",
    "            titles.append(match.group(1))\n",
    "        else:\n",
    "            titles.append(x)\n",
    "    \n",
    "    first_25_titles = titles[:25]\n",
    "    \n",
    "    spans = soup.find_all(\"span\", class_ = \"sc-300a8231-7 eaXxft dli-title-metadata-item\")\n",
    "\n",
    "    years = []\n",
    "    \n",
    "    for span in spans:\n",
    "        text = span.text\n",
    "        if text.isdigit() and len(text) == 4:\n",
    "            years.append(text)\n",
    "\n",
    "    spans_ratings = soup.find_all(\"span\", class_ = \"ipc-rating-star--rating\")\n",
    "\n",
    "    ratings = []\n",
    "\n",
    "    for span in spans_ratings:\n",
    "        text = span.get_text()\n",
    "        numbers = re.findall(r'\\d+\\.\\d+', text)\n",
    "        ratings.extend(float(num) for num in numbers)\n",
    "    \n",
    "    durations = [span.get_text(strip=True) for span in spans if 'h' in span.get_text() or 'm' in span.get_text()]\n",
    "\n",
    "    div_descriptions = soup.find_all('div', class_='ipc-html-content-inner-div')\n",
    "\n",
    "    descriptions = []\n",
    "\n",
    "    for div in div_descriptions:\n",
    "        description = div.get_text()\n",
    "        descriptions.append(description)\n",
    "\n",
    "    spans_votes = soup.find_all(\"span\", class_ = \"ipc-rating-star--voteCount\")\n",
    "\n",
    "    votes = []\n",
    "\n",
    "    for span in spans_votes:\n",
    "        text = span.get_text()\n",
    "        match = re.match(r'\\s*\\(([\\d.]+)([KM])\\)', text)\n",
    "        if match:\n",
    "            number = float(match.group(1))\n",
    "            unit = match.group(2)\n",
    "            \n",
    "            if unit == 'K':\n",
    "                votes.append(int(number * 1_000))\n",
    "            elif unit == 'M':\n",
    "                votes.append(int(number * 1_000_000))\n",
    "\n",
    "    data = {\n",
    "        'Movie Nr': movie_nr,\n",
    "        'Title': first_25_titles,\n",
    "        'Year': years,\n",
    "        'Rating': ratings,\n",
    "        'Runtime (min)': durations,\n",
    "        'Description': descriptions,\n",
    "        'Votes': votes\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "url = create_imdb_url()\n",
    "df = scrape_imdb(url)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f57664-5d78-4998-aaa0-d16dbaf2c051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b08f93-d793-4153-9ba2-4f151d76bd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3740739-3062-4f67-a24e-ea0eb5d18582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028b4aa-812d-47f4-89e5-a2c1d6280ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bfddbd-ab4a-4160-a5c4-13342aeb7c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df02ce-2a46-4930-b7f0-b4df1dc6fe71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f566d48-7248-4007-9827-7bb218e5cc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1709d3-7aae-4085-9413-1b6a8195689a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b816cec-8750-40a9-a400-44d107aea2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
